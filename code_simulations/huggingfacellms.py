# -*- coding: utf-8 -*-
"""HuggingFaceLLMs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vQKuLF_Utixy0AxQvd4f8jggaUGQXwnK

This is a code where we're testing multiple LLM models.
"""

!pip install gradio

from PIL import Image

image = Image.open('img2.png')

prompt = "Analyze this network diagram and list the network only, e.g. Q + W -> R, P.S. the reaction'x' are operators, if there are multiple reactions give them with comma separations, like A -> B, B -> C, etc."

response = model.generate_content([prompt, image])

# print("Model's response:")
print(response.text)

!pip install transformers torch Pillow

from transformers import pipeline
from PIL import Image

# Open your image
image = Image.open('img2.png')

!pip install pytesseract

"""miscrosoft/layoutlmv3-base model"""

from transformers import LayoutLMv3Processor, LayoutLMv3ForQuestionAnswering
from PIL import Image
import torch

# Load image (replace 'path_to_image' with your image path)
image = image.convert("RGB")

# Define your question
question = (
    "Analyze this network diagram and list the network only, "
    "e.g. Q + W -> R, P.S. the reaction 'x' are operators, "
    "if there are multiple reactions give them with comma separations, "
    "like A -> B, B -> C, etc."
)

# Load processor and model
processor = LayoutLMv3Processor.from_pretrained("microsoft/layoutlmv3-base", apply_ocr=True)
model = LayoutLMv3ForQuestionAnswering.from_pretrained("microsoft/layoutlmv3-base")

# Prepare inputs
inputs = processor(image, question, return_tensors="pt")

# Run inference
with torch.no_grad():
    outputs = model(**inputs)
    start_logits = outputs.start_logits
    end_logits = outputs.end_logits

# Decode the answer
start_index = torch.argmax(start_logits)
end_index = torch.argmax(end_logits)
answer_tokens = inputs["input_ids"][0][start_index:end_index + 1]
answer = processor.tokenizer.decode(answer_tokens, skip_special_tokens=True)

# Print answer
print(answer)

"""naver-clova-ix/donut-base-finetuned-docvqa model"""

# Load the Donut document question answering pipeline
pipe = pipeline(
    task="document-question-answering",
    model="naver-clova-ix/donut-base-finetuned-docvqa"
)
# Set your prompt/question
prompt = (
    "Analyze this network diagram and list the network only, "
    "e.g. Q + W -> R, P.S. the reaction 'x' are operators, "
    "if there are multiple reactions give them with comma separations, "
    "like A -> B, B -> C, etc."
)
# Run inference
result = pipe(image=image, question=prompt)

# Print the model's answer
print(result[0]['answer'])

"""google/pix2struct-docvqa-base model"""

from transformers import Pix2StructProcessor, Pix2StructForConditionalGeneration
from PIL import Image
import torch

# Load image (replace 'path_to_image' with your actual image path)
# image = Image.open("path_to_image").convert("RGB")

# Define your question/prompt
question = (
    "Analyze this network diagram and list the network only, "
    "e.g. Q + W -> R, P.S. the reaction 'x' are operators, "
    "if there are multiple reactions give them with comma separations, "
    "like A -> B, B -> C, etc."
)

# Load the Pix2Struct model and processor
processor = Pix2StructProcessor.from_pretrained("google/pix2struct-docvqa-base")
model = Pix2StructForConditionalGeneration.from_pretrained("google/pix2struct-docvqa-base")

# Prepare input for the model
inputs = processor(images=image, text=question, return_tensors="pt")

# Run inference
with torch.no_grad():
    predictions = model.generate(**inputs)

# Decode the output
answer = processor.decode(predictions[0], skip_special_tokens=True)

# Print the model's answer
print(answer)

result = pipe(image=image, question=prompt)
print(result[0]['answer'])

# âœ… Gradio App with Support for Multi-Reactant Networks (e.g. A + B -> AB)

from transformers import pipeline
import gradio as gr
import networkx as nx
import sympy as sp
from collections import defaultdict
import re

# --- Parsing Functions ---
def parse_species(expr):
    # e.g., "A + B" -> ["A", "B"]
    return [s.strip() for s in re.split(r'\s*[\+\-]\s*', expr)]

def parse_network(input_string):
    edges = []
    reversible_edges = []

    for part in input_string.split(','):
        part = part.strip()
        if '<->' in part:
            lhs, rhs = part.split('<->')
            lhs_species = parse_species(lhs)
            rhs_species = parse_species(rhs)
            reversible_edges.append((lhs_species, rhs_species))
        elif '->' in part:
            lhs, rhs = part.split('->')
            lhs_species = parse_species(lhs)
            rhs_species = parse_species(rhs)
            edges.append((lhs_species, rhs_species))

    return edges, reversible_edges

def build_graph(edges, reversible_edges):
    G = nx.DiGraph()
    for a, b in edges:
        lhs = " + ".join(a)
        rhs = " + ".join(b)
        G.add_edge(lhs, rhs)
    for a, b in reversible_edges:
        lhs = " + ".join(a)
        rhs = " + ".join(b)
        G.add_edge(lhs, rhs)
        G.add_edge(rhs, lhs)
    return G

def analyze_graph(G):
    return {
        "nodes": list(G.nodes),
        "edges": list(G.edges),
        "num_nodes": G.number_of_nodes(),
        "num_edges": G.number_of_edges(),
        "is_cyclic": not nx.is_directed_acyclic_graph(G)
    }

# --- ODE Generator for Complex Reactions ---
def mass_action_odes(edges, reversible_edges):
    species = set()
    odes = defaultdict(lambda: 0)
    rate_counter = 1

    def term(species_list):
        term_expr = 1
        for s in species_list:
            sym = sp.symbols(s)
            species.add(sym)
            term_expr *= sym
        return term_expr

    for lhs_species, rhs_species in edges:
        k = sp.symbols(f'k{rate_counter}')
        rate_counter += 1

        flux = k * term(lhs_species)
        for s in lhs_species:
            sym = sp.symbols(s)
            odes[sym] -= flux
        for s in rhs_species:
            sym = sp.symbols(s)
            odes[sym] += flux

    for lhs_species, rhs_species in reversible_edges:

        kf = sp.symbols(f'k{rate_counter}')
        rate_counter += 1
        kr = sp.symbols(f'k{rate_counter}')
        rate_counter += 1

        forward_flux = kf * term(lhs_species)
        reverse_flux = kr * term(rhs_species)

        for s in lhs_species:
            sym = sp.symbols(s)
            odes[sym] -= forward_flux
            odes[sym] += reverse_flux
        for s in rhs_species:
            sym = sp.symbols(s)
            odes[sym] += forward_flux
            odes[sym] -= reverse_flux

    return dict(odes)

def format_odes(odes):
    return "\n".join([f"d{var}/dt = {sp.simplify(expr)}" for var, expr in odes.items()])

def compute_jacobian(odes):
    variables = list(odes.keys())
    F = sp.Matrix([odes[var] for var in variables])
    J = F.jacobian(variables)
    return sp.pretty(J)

qa = pipeline("text2text-generation", model="google/flan-t5-base")
def process_network(input_string, query):
    edges, reversible_edges = parse_network(input_string)
    G = build_graph(edges, reversible_edges)
    info = analyze_graph(G)

    if 'ode' in query.lower():
        ode_sys = mass_action_odes(edges, reversible_edges)
        return format_odes(ode_sys)

    elif 'jacobian' in query.lower():
        ode_sys = mass_action_odes(edges, reversible_edges)
        return f"Jacobian Matrix:\n{compute_jacobian(ode_sys)}"

    elif 'variables' in query.lower():
        return f"There are {info['num_nodes']} variables: {info['nodes']}"

    elif 'edges' in query.lower():
        return f"Edges: {info['edges']}"

    elif 'cyclic' in query.lower():
        cycles = list(nx.simple_cycles(G))
        if cycles:
            cycles_str = "\n".join([" -> ".join(cycle + [cycle[0]]) for cycle in cycles])
            return f"Cycles found:\n{cycles_str}"
        else:
            return "No cycles found."

    else:
        prompt = f"Given the network with nodes: {info['nodes']} and edges: {info['edges']}, answer the query: {query}"
        answer = qa(prompt, max_length=128)[0]['generated_text']
        return answer

# iface = gr.Interface(
#     fn=process_network,
#     inputs=[
#         gr.Textbox(label="Network Description", placeholder="Example: A->B, B<->C, A + B -> AB"),
#         gr.Textbox(label="Query", placeholder="Ask about variables, ODEs, Jacobian, etc.")
#     ],
#     outputs="text",
#     title="Biological Network Analyzer",
#     description="Now supports multi-reactant reactions like 'A + B -> AB'"
# )

# iface.launch()

print(response.text)
print(process_network(response.text, "give the ode of the network"))

